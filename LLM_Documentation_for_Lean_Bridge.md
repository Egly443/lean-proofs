This is the final piece of the puzzle. This documentation is designed specifically to be read by an LLM (like Claude Code, Cursor, or a custom agent) to teach it how to "drive" the tools you have built.  
Save the following content as README\_for\_LLMs.md in your project folder. When you start a new session with Claude Code, you can simply say: *"Read README\_for\_LLMs.md and then use the tools to solve Test.lean."*

# ---

**Lean 4 Neuro-Symbolic Bridge: Technical Documentation**

## **1\. System Overview**

This toolset provides a persistent, stateful interface between an external agent (LLM/Script) and the Lean 4 formal verification environment. It bypasses the overhead of restarting Lean for every command by maintaining a long-running background process with loaded libraries (e.g., Mathlib).

### **Architecture**

* **Server (lean\_bridge.py):** Wraps the Lean repl binary. It manages input/output streams, parsing Lean's JSON output into structured data, and maintaining the process lifecycle.  
* **Client (agent.py / CLI):** Sends JSON requests to the server via a Unix Domain Socket (.lean\_bridge.sock).  
* **State Management:** Lean uses integer IDs (proofState) to track the context. The agent must track these IDs to navigate the proof tree.

## ---

**2\. Tool Reference: lean\_bridge.py**

**Role:** The Infrastructure. It must be running for any interaction to happen.

### **A. Starting the Server**

The server compiles imports once and then waits for commands.

Bash

python lean\_bridge.py server \<filename.lean\>

* **Output:** Prints \[\*\] Server ready when initialization is complete.  
* **Note:** This terminal will be blocked. Run client commands in a separate terminal.

### **B. Client Commands (CLI)**

Used to send atomic requests to the running server.  
**1\. Execute Command (cmd)**  
Runs a Lean command (definitions, evaluations, starting proofs).

Bash

python lean\_bridge.py cmd "\<lean\_code\>"

* **Use Case:** \#eval 1+1, defining helper functions, or starting a theorem (example ... := by sorry).  
* **Return:** JSON containing messages and sorries (proof holes).

**2\. Execute Tactic (tactic)**  
Applies a proof step to a specific state.

Bash

python lean\_bridge.py tactic "\<tactic\_code\>" \--id \<state\_id\>

* **Required Argument:** \--id \<int\> (The Proof State ID returned by the previous command).  
* **Return:**  
  * success: Returns new goals and new\_state\_id.  
  * error: Returns the Lean error message (e.g., "tactic failed").

**3\. Stop Server**  
Safely terminates the background process.

Bash

python lean\_bridge.py stop

### **C. JSON Response Structure**

The bridge standardizes Lean's output. Agents should parse these fields:

* **Success (Goal Pending):**  
  JSON  
  {  
    "status": "success",  
    "goals": \["n : Nat ‚ä¢ n \+ 0 \= n"\],  
    "new\_state\_id": 5  
  }

* **Success (Proof Complete):**  
  JSON  
  {  
    "status": "success",  
    "goals": \[\],  // Empty list \= Q.E.D.  
    "new\_state\_id": 6  
  }

* **Initial Proof State (from cmd):**  
  JSON  
  {  
    "status": "success",  
    "response": {  
      "sorries": \[  
        {"proofState": 0, "goal": "..."}  
      \]  
    }  
  }

## ---

**3\. Tool Reference: agent.py**

**Role:** The Search Algorithm (Brain).  
This script implements a **Breadth-First Search (BFS)** strategy. It automatically explores the proof tree generated by lean\_bridge.py.

### **How to Configure for an LLM**

The LLM is expected to modify the TACTIC\_LIBRARY list in agent.py before running it, or write a custom driver based on this class.  
**Key Components:**

1. **TACTIC\_LIBRARY:** A python list of strings. The agent tries *every* tactic in this list against the current goal.  
   * *LLM Action:* Update this list with context-relevant tactics (e.g., induction n, apply And.intro) before running.  
2. **THEOREM:** The starting proof statement.  
   * *LLM Action:* Set this to the problem statement (ending with := by sorry).

### **Algorithm Logic**

1. **Queue:** Starts with the initial proofState from the sorry.  
2. **Expansion:** Pops a state, tries all tactics.  
3. **Branching:** If a tactic succeeds (no error), the new state is added to the queue.  
4. **Loop Detection:** It stores hashes of goal states to prevent infinite loops (e.g., rw \[add\_comm\] twice).  
5. **Success:** Stops immediately when goals: \[\] is found.

## ---

**4\. Workflow for LLMs (How to drive this)**

If you are an AI assistant (Claude/GPT) reading this, follow this protocol to solve a proof:  
**Phase 1: Setup**

1. **Read the File:** Inspect the target .lean file to understand imports and available theorems.  
2. **Start Server:** Run python lean\_bridge.py server \<file\> & (background) or ask the user to run it. Wait for "Server ready".

**Phase 2: Exploration**

1. **Check Capability:** Send a simple command like \#eval 1 to ensure the connection is active.  
2. **Initialize Proof:** Send the theorem using cmd ending with := by sorry.  
3. **Parse ID:** Extract the proofState ID from the JSON response.

**Phase 3: The Tactic Loop**  
You have two options to solve the proof:

* **Option A (Manual Step-by-Step):**  
  1. Look at the goal string.  
  2. Construct a tactic string (e.g., intro h).  
  3. Run python lean\_bridge.py tactic "intro h" \--id \<CURRENT\_ID\>.  
  4. Analyze the JSON result.  
     * If goals is empty: **Done.**  
     * If goals changed: Update CURRENT\_ID and repeat.  
     * If error: Try a different tactic on the *same* ID.  
* **Option B (Agent Automation):**  
  1. Modify agent.py: Insert the theorem and a list of probable tactics into the script.  
  2. Run python agent.py.  
  3. Read the stdout. It will explore the tree for you and print the solution path if found.

**Phase 4: Finalization**

1. Once the tactic sequence is found (e.g., intro n, induction n, simp), modify the original .lean file.  
2. Replace := by sorry with the proven block:  
   Lean  
   := by  
     intro n  
     induction n  
     simp

3. Stop the server: python lean\_bridge.py stop.

## ---

**5\. Troubleshooting & Edge Cases**

* **"Broken Pipe" / "Connection Refused":**  
  The server has crashed or isn't running. Check the server terminal for Lean errors (e.g., invalid imports). Restart the server.  
* **"Expecting value..." (JSON Error):**  
  The bridge received non-JSON output (like a compiler warning) mixed with the response. The \_read\_lean\_output function in the bridge is designed to skip this, but severe crashes may still cause it.  
* **Multiple Goals:**  
  If the response contains \["goal1", "goal2"\], the agent is currently focusing on goal1. The ID refers to the *entire set* of goals. Solving goal1 will return a new state containing only \["goal2"\].  
* **Heavy Imports:**  
  Initializing Mathlib can take 30s+. If the client times out, increase the timeout in lean\_bridge.py or wait longer before sending the first command.